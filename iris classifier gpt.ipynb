{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn    \n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([16, 4])------torch.Size([16])\n",
      "torch.Size([8, 4])------torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "X,y = load_iris().data, load_iris().target\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train = torch.tensor(X_train,dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train,dtype=torch.long)\n",
    "X_test = torch.tensor(X_test,dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test,dtype=torch.long)\n",
    "\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "\n",
    "for i,(inputs,labels) in enumerate(train_loader):\n",
    "    print(f\"{inputs.shape}------{labels.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IrisNet(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.fc1 = nn.Linear(4,3)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = IrisNet()\n",
    "loss_fcn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(),lr=0.01,momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], | Loss: 0.1416, | training_accuracy: 96.67%\n",
      "Epoch [2/100], | Loss: 0.1409, | training_accuracy: 96.67%\n",
      "Epoch [3/100], | Loss: 0.1402, | training_accuracy: 96.67%\n",
      "Epoch [4/100], | Loss: 0.1394, | training_accuracy: 96.67%\n",
      "Epoch [5/100], | Loss: 0.1388, | training_accuracy: 96.67%\n",
      "Epoch [6/100], | Loss: 0.1382, | training_accuracy: 96.67%\n",
      "Epoch [7/100], | Loss: 0.1376, | training_accuracy: 96.67%\n",
      "Epoch [8/100], | Loss: 0.1369, | training_accuracy: 96.67%\n",
      "Epoch [9/100], | Loss: 0.1362, | training_accuracy: 96.67%\n",
      "Epoch [10/100], | Loss: 0.1357, | training_accuracy: 96.67%\n",
      "Epoch [11/100], | Loss: 0.1353, | training_accuracy: 96.67%\n",
      "Epoch [12/100], | Loss: 0.1346, | training_accuracy: 96.67%\n",
      "Epoch [13/100], | Loss: 0.1339, | training_accuracy: 96.67%\n",
      "Epoch [14/100], | Loss: 0.1334, | training_accuracy: 96.67%\n",
      "Epoch [15/100], | Loss: 0.1330, | training_accuracy: 96.67%\n",
      "Epoch [16/100], | Loss: 0.1324, | training_accuracy: 96.67%\n",
      "Epoch [17/100], | Loss: 0.1317, | training_accuracy: 96.67%\n",
      "Epoch [18/100], | Loss: 0.1312, | training_accuracy: 96.67%\n",
      "Epoch [19/100], | Loss: 0.1307, | training_accuracy: 96.67%\n",
      "Epoch [20/100], | Loss: 0.1301, | training_accuracy: 96.67%\n",
      "Epoch [21/100], | Loss: 0.1298, | training_accuracy: 96.67%\n",
      "Epoch [22/100], | Loss: 0.1294, | training_accuracy: 96.67%\n",
      "Epoch [23/100], | Loss: 0.1288, | training_accuracy: 96.67%\n",
      "Epoch [24/100], | Loss: 0.1282, | training_accuracy: 96.67%\n",
      "Epoch [25/100], | Loss: 0.1278, | training_accuracy: 96.67%\n",
      "Epoch [26/100], | Loss: 0.1272, | training_accuracy: 96.67%\n",
      "Epoch [27/100], | Loss: 0.1267, | training_accuracy: 96.67%\n",
      "Epoch [28/100], | Loss: 0.1263, | training_accuracy: 96.67%\n",
      "Epoch [29/100], | Loss: 0.1257, | training_accuracy: 96.67%\n",
      "Epoch [30/100], | Loss: 0.1253, | training_accuracy: 96.67%\n",
      "Epoch [31/100], | Loss: 0.1249, | training_accuracy: 96.67%\n",
      "Epoch [32/100], | Loss: 0.1245, | training_accuracy: 96.67%\n",
      "Epoch [33/100], | Loss: 0.1240, | training_accuracy: 96.67%\n",
      "Epoch [34/100], | Loss: 0.1236, | training_accuracy: 96.67%\n",
      "Epoch [35/100], | Loss: 0.1231, | training_accuracy: 96.67%\n",
      "Epoch [36/100], | Loss: 0.1227, | training_accuracy: 96.67%\n",
      "Epoch [37/100], | Loss: 0.1223, | training_accuracy: 96.67%\n",
      "Epoch [38/100], | Loss: 0.1219, | training_accuracy: 96.67%\n",
      "Epoch [39/100], | Loss: 0.1214, | training_accuracy: 96.67%\n",
      "Epoch [40/100], | Loss: 0.1212, | training_accuracy: 96.67%\n",
      "Epoch [41/100], | Loss: 0.1206, | training_accuracy: 96.67%\n",
      "Epoch [42/100], | Loss: 0.1202, | training_accuracy: 96.67%\n",
      "Epoch [43/100], | Loss: 0.1200, | training_accuracy: 96.67%\n",
      "Epoch [44/100], | Loss: 0.1195, | training_accuracy: 96.67%\n",
      "Epoch [45/100], | Loss: 0.1191, | training_accuracy: 96.67%\n",
      "Epoch [46/100], | Loss: 0.1189, | training_accuracy: 96.67%\n",
      "Epoch [47/100], | Loss: 0.1185, | training_accuracy: 96.67%\n",
      "Epoch [48/100], | Loss: 0.1181, | training_accuracy: 96.67%\n",
      "Epoch [49/100], | Loss: 0.1177, | training_accuracy: 96.67%\n",
      "Epoch [50/100], | Loss: 0.1173, | training_accuracy: 96.67%\n",
      "Epoch [51/100], | Loss: 0.1169, | training_accuracy: 96.67%\n",
      "Epoch [52/100], | Loss: 0.1166, | training_accuracy: 96.67%\n",
      "Epoch [53/100], | Loss: 0.1163, | training_accuracy: 96.67%\n",
      "Epoch [54/100], | Loss: 0.1161, | training_accuracy: 96.67%\n",
      "Epoch [55/100], | Loss: 0.1155, | training_accuracy: 96.67%\n",
      "Epoch [56/100], | Loss: 0.1157, | training_accuracy: 96.67%\n",
      "Epoch [57/100], | Loss: 0.1148, | training_accuracy: 96.67%\n",
      "Epoch [58/100], | Loss: 0.1145, | training_accuracy: 96.67%\n",
      "Epoch [59/100], | Loss: 0.1141, | training_accuracy: 96.67%\n",
      "Epoch [60/100], | Loss: 0.1140, | training_accuracy: 96.67%\n",
      "Epoch [61/100], | Loss: 0.1135, | training_accuracy: 96.67%\n",
      "Epoch [62/100], | Loss: 0.1132, | training_accuracy: 96.67%\n",
      "Epoch [63/100], | Loss: 0.1129, | training_accuracy: 96.67%\n",
      "Epoch [64/100], | Loss: 0.1127, | training_accuracy: 96.67%\n",
      "Epoch [65/100], | Loss: 0.1122, | training_accuracy: 96.67%\n",
      "Epoch [66/100], | Loss: 0.1120, | training_accuracy: 96.67%\n",
      "Epoch [67/100], | Loss: 0.1117, | training_accuracy: 96.67%\n",
      "Epoch [68/100], | Loss: 0.1114, | training_accuracy: 96.67%\n",
      "Epoch [69/100], | Loss: 0.1113, | training_accuracy: 96.67%\n",
      "Epoch [70/100], | Loss: 0.1110, | training_accuracy: 96.67%\n",
      "Epoch [71/100], | Loss: 0.1105, | training_accuracy: 96.67%\n",
      "Epoch [72/100], | Loss: 0.1103, | training_accuracy: 96.67%\n",
      "Epoch [73/100], | Loss: 0.1100, | training_accuracy: 96.67%\n",
      "Epoch [74/100], | Loss: 0.1097, | training_accuracy: 96.67%\n",
      "Epoch [75/100], | Loss: 0.1094, | training_accuracy: 96.67%\n",
      "Epoch [76/100], | Loss: 0.1091, | training_accuracy: 96.67%\n",
      "Epoch [77/100], | Loss: 0.1088, | training_accuracy: 96.67%\n",
      "Epoch [78/100], | Loss: 0.1085, | training_accuracy: 96.67%\n",
      "Epoch [79/100], | Loss: 0.1084, | training_accuracy: 96.67%\n",
      "Epoch [80/100], | Loss: 0.1080, | training_accuracy: 96.67%\n",
      "Epoch [81/100], | Loss: 0.1077, | training_accuracy: 96.67%\n",
      "Epoch [82/100], | Loss: 0.1077, | training_accuracy: 96.67%\n",
      "Epoch [83/100], | Loss: 0.1073, | training_accuracy: 96.67%\n",
      "Epoch [84/100], | Loss: 0.1070, | training_accuracy: 96.67%\n",
      "Epoch [85/100], | Loss: 0.1067, | training_accuracy: 96.67%\n",
      "Epoch [86/100], | Loss: 0.1065, | training_accuracy: 96.67%\n",
      "Epoch [87/100], | Loss: 0.1062, | training_accuracy: 96.67%\n",
      "Epoch [88/100], | Loss: 0.1060, | training_accuracy: 96.67%\n",
      "Epoch [89/100], | Loss: 0.1057, | training_accuracy: 96.67%\n",
      "Epoch [90/100], | Loss: 0.1055, | training_accuracy: 96.67%\n",
      "Epoch [91/100], | Loss: 0.1052, | training_accuracy: 96.67%\n",
      "Epoch [92/100], | Loss: 0.1050, | training_accuracy: 96.67%\n",
      "Epoch [93/100], | Loss: 0.1048, | training_accuracy: 96.67%\n",
      "Epoch [94/100], | Loss: 0.1046, | training_accuracy: 96.67%\n",
      "Epoch [95/100], | Loss: 0.1042, | training_accuracy: 96.67%\n",
      "Epoch [96/100], | Loss: 0.1040, | training_accuracy: 96.67%\n",
      "Epoch [97/100], | Loss: 0.1041, | training_accuracy: 96.66%\n",
      "Epoch [98/100], | Loss: 0.1036, | training_accuracy: 96.65%\n",
      "Epoch [99/100], | Loss: 0.1034, | training_accuracy: 96.65%\n",
      "Epoch [100/100], | Loss: 0.1032, | training_accuracy: 96.65%\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "correct = 0\n",
    "total = 0\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        _,predicted = torch.max(outputs.data,1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        train_acc = correct/total * 100\n",
    "        \n",
    "        loss = loss_fcn(outputs,labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss+= loss.item() * inputs.size(0)\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}], | Loss: {epoch_loss:.4f}, | training_accuracy: {train_acc:.2f}%')\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _ , predicted = torch.max(outputs.data, 1)  # Get the index of the max logit\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "acc = (correct / total) * 100  \n",
    "print(f'Test Accuracy: {acc:.2f}%')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
